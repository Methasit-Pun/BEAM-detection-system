<div align="center">

# üõ¥ E-Scooter Safety Detection System

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.10+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.0+-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.5+-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)](https://opencv.org/)
[![NVIDIA Jetson](https://img.shields.io/badge/NVIDIA-Jetson_Nano-76B900?style=for-the-badge&logo=nvidia&logoColor=white)](https://developer.nvidia.com/embedded/jetson-nano)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/Status-Deployed-success?style=for-the-badge)](https://github.com/Methasit-Pun/BEAM-detection-system)
[![Accuracy](https://img.shields.io/badge/Accuracy-90.74%25-brightgreen?style=for-the-badge)](https://github.com/Methasit-Pun/BEAM-detection-system)

**Real-time computer vision system for detecting multi-rider e-scooter violations**

**Deployed at Chulalongkorn University | 90.74% Detection Accuracy | 87% Violation Reduction in 5 Days**

[Features](#-features) ‚Ä¢ [Architecture](#-system-architecture) ‚Ä¢ [Results](#-key-results) ‚Ä¢ [Installation](#-installation) ‚Ä¢ [Documentation](#-implementation)

</div>

---

## üìã Table of Contents

- [üéØ Problem Statement](#-problem-statement)
- [üí° Solution Overview](#-solution-overview)
- [üìä Key Results](#-key-results)
- [üèÜ Features](#-features)
- [‚öôÔ∏è Technical Stack](#Ô∏è-technical-stack)
- [üèóÔ∏è System Architecture](#Ô∏è-system-architecture)
- [üíª Implementation](#-implementation)
- [üß™ Field Testing Results](#-field-testing-results)
- [üöÄ Installation](#-installation)
- [üîÆ Future Work](#-future-work)
- [ü§ù Contributing](#-contributing)
- [üìÑ License](#-license)

---

## üéØ Problem Statement

<img width="600" alt="Problem: Multiple riders on single e-scooters increase accident risk" src="https://github.com/user-attachments/assets/55af3d25-402e-47ad-baff-3d2de3b7a6c1" />

Multiple riders on single e-scooters create safety hazards on campus. This common violation increases accident risk and requires automated monitoring.

---

## üí° Solution Overview

<img width="600" alt="Detection system with real-time audio alerts" src="https://github.com/user-attachments/assets/d1a7da82-4f8e-4802-9716-dd93951eca8c" />

Real-time computer vision system that:
- Detects e-scooters and counts riders using SSD-MobileNet
- Triggers audio alerts when 2+ riders detected
- Runs on Jetson Nano for edge deployment
- Processes video at 15-20 FPS

---

## üìä Key Results

<div align="center">

### üéØ Performance Metrics

| Metric | Value | Impact |
|--------|-------|--------|
| **Detection Accuracy** | 90.74% | High reliability in real-world conditions |
| **Violation Reduction** | 31% ‚Üí 4% | 87% decrease in 5 days |
| **Processing Speed** | 15-20 FPS | Real-time monitoring capability |
| **Response Time** | <200ms | Instant alert generation |
| **False Positive Rate** | <10% | Minimal incorrect alerts |

</div>

**Field Deployment Statistics:**
- üìπ Monitored 3-25 scooters per session
- ‚ö†Ô∏è Peak: 6 multi-rider incidents detected in single session
- üìà Alert-to-incident correlation: >95%
- üë• User compliance: Variable (0-50%), decreasing trend over time
- ‚è∞ Test period: 5 days across multiple campus locations
- üïê Test hours: Morning (08:00-10:00) and Evening (16:00-18:00)

<img width="800" alt="Experiment results showing detection accuracy over multiple sessions" src="https://github.com/user-attachments/assets/071c1ca3-d875-478b-bcca-7f1b3a397e19" />

---

## üèÜ Features

- **Real-time Detection:** Processes video at 15-20 FPS on edge hardware
- **High Accuracy:** 90.74% detection accuracy in real-world deployment
- **Instant Alerts:** Audio notifications triggered within 200ms of detection
- **Edge Computing:** Runs entirely on Jetson Nano without cloud dependency
- **Custom Dataset:** Trained on 100+ campus-specific labeled images
- **Scalable Architecture:** Easily deployable across multiple locations

---

## ‚öôÔ∏è Technical Stack

<table>
<tr>
<td width="50%">

### üîß Hardware
- **Computing:** NVIDIA Jetson Nano 4GB
- **Camera:** IMX219 CSI Camera (1080p)
- **Audio:** USB Speaker/Buzzer
- **Power:** 5V 4A DC Adapter
- **Storage:** 32GB microSD

</td>
<td width="50%">

### üíª Software
- **Training:** PyTorch 1.10+
- **Deployment:** TensorFlow 2.0+
- **Vision:** OpenCV 4.5+
- **Language:** Python 3.8+
- **Audio:** PyAudio
- **Data:** NumPy, Pandas

</td>
</tr>
<tr>
<td width="50%">

### üß† Model Architecture
- **Base Model:** SSD-MobileNet
- **Input Size:** 300√ó300 RGB
- **Framework:** PyTorch ‚Üí ONNX
- **Inference Time:** ~50ms per frame
- **Dataset Format:** Pascal VOC

</td>
<td width="50%">

### üõ†Ô∏è Development Tools
- **Version Control:** Git/GitHub
- **Container:** Docker (optional)
- **IDE:** VS Code, Jupyter
- **Annotation:** camera-capture tool
- **Monitoring:** TensorBoard

</td>
</tr>
</table>

---

## üèóÔ∏è System Architecture

### Software Architecture

```mermaid
graph TB
    subgraph "Input Layer"
        A[Camera Feed CSI/USB] --> B[Video Capture OpenCV]
    end
    
    subgraph "Processing Pipeline"
        B --> C[Frame Preprocessing]
        C --> D[SSD-MobileNet ONNX]
        D --> E[Object Detection]
        E --> F[Bounding Box Extraction]
    end
    
    subgraph "Detection Logic"
        F --> G[Scooter Detection]
        F --> H[Person Detection]
        G --> I[Overlap Analysis]
        H --> I
        I --> J{Count Riders}
    end
    
    subgraph "Alert System"
        J -->|>= 2 Riders| K[Violation Detected]
        J -->|< 2 Riders| L[Normal Operation]
        K --> M[Trigger Audio Alert PyAudio]
        K --> N[Visual Warning Overlay]
    end
    
    subgraph "Output & Logging"
        M --> O[Speaker Output]
        N --> P[Display Frame]
        K --> Q[Log Violation Data]
    end
    
    style K fill:#ff6b6b
    style L fill:#51cf66
    style D fill:#339af0
```

### Pipeline Flow

1. **Video Acquisition** ‚Üí Camera captures 1080p video at 30 FPS
2. **Frame Processing** ‚Üí Resize to 300√ó300, normalize pixel values
3. **Inference** ‚Üí SSD-MobileNet processes frame (~50ms)
4. **Post-Processing** ‚Üí Extract bounding boxes with confidence scores
5. **Violation Logic** ‚Üí Check spatial overlap between scooter and person boxes
6. **Alert Generation** ‚Üí Trigger audio if multi-rider detected
7. **Display & Logging** ‚Üí Render annotated frame and log event

### Key Components

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Detection Model** | SSD-MobileNet (ONNX) | Real-time object detection |
| **Inference Engine** | TensorRT / TensorFlow Lite | Optimized inference on Jetson |
| **Video Handler** | OpenCV VideoCapture | Frame acquisition and processing |
| **Violation Detector** | Custom Python Logic | Spatial overlap analysis |
| **Alert System** | PyAudio + Wave | Audio alert playback |
| **Logger** | Python Logging | Event tracking and statistics |

### Data Flow

```
Camera ‚Üí Frame Buffer ‚Üí Preprocessing ‚Üí Neural Network ‚Üí 
Detected Objects ‚Üí Violation Check ‚Üí Alert/Log ‚Üí Display
```

**Processing Stages:**
- **Input:** 1920√ó1080 RGB frame
- **Preprocessed:** 300√ó300 RGB tensor
- **Detection:** Bounding boxes + class labels + confidence scores
- **Analysis:** Rider count per scooter
- **Output:** Alert trigger + annotated frame

### Hardware Setup
<img width="600" alt="Hardware design and component layout" src="https://github.com/user-attachments/assets/1d196ba9-d673-4242-86cc-1163464ac2ee" />

### Deployed System
<img width="600" alt="Physical deployment on campus" src="https://github.com/user-attachments/assets/25a2029e-c198-44e1-9631-e92044e9adc7" />

### Experiment Locations
<img width="600" alt="Test locations across campus" src="https://github.com/user-attachments/assets/53da211a-1cb4-4a47-868f-0b26c0ac538a" />

---

## üíª Implementation


### Dataset Categories
- Empty scooter
- Single rider (compliant)
- Multiple riders (violation)
- *(Future)* Speed detection
- *(Future)* Direction compliance


### Data Collection Workflow

**1. Setup Dataset Structure**
```bash
cd jetson-inference/python/training/detection/ssd/data
mkdir <your-dataset>
cd <your-dataset>
echo -e "empty\nsingle_rider\nmulti_rider" > labels.txt
```


**2. Capture & Label Images**

Using jetson-inference camera-capture tool:
```bash
camera-capture csi://0              # MIPI CSI camera
camera-capture /dev/video0          # USB camera
```
- Set mode to "Detection" in UI
- Freeze frame, draw bounding boxes
- Assign class labels
- Save and repeat

> **Note:** We initially tried [Kaggle e-scooter dataset](https://www.kaggle.com/datasets/trainingdatapro/electric-scooters-tracking) but accuracy was insufficient. Custom campus-specific data performed better.


<div align="center">

<img height="300" alt="Sample from custom dataset" src="https://github.com/user-attachments/assets/3e1afe9c-2ebf-410c-af3b-7f3ac44fb902" />
<img height="300" alt="Labeled training sample" src="https://github.com/user-attachments/assets/bf3e4fbb-1000-46c9-a4df-12effa8d753d" />

</div>


**3. Train Model**
```bash
cd jetson-inference/python/training/detection/ssd
python3 train_ssd.py --dataset-type=voc --data=data/<your-dataset> --model-dir=models/<your-model>
```

**4. Export to ONNX**
```bash
python3 onnx_export.py --model-dir=models/<your-model>
```

**5. Deploy Detection**
```bash
NET=models/<your-model>
detectnet --model=$NET/ssd-mobilenet.onnx --labels=$NET/labels.txt \
          --input-blob=input_0 --output-cvg=scores --output-bbox=boxes \
          csi://0
```

**6. Audio Alert Integration**
```python
import pyaudio
import wave

def trigger_alert():
    """Play alert sound when violation detected"""
    audio_file = "violation_alert.wav"
    wf = wave.open(audio_file, 'rb')
    p = pyaudio.PyAudio()
    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),
                    channels=wf.getnchannels(),
                    rate=wf.getframerate(),
                    output=True)
    stream.write(wf.readframes(1024))
```

### Technical Resources
- **Similar Implementation:** [Scooter Radar Backend](https://github.com/Scooter-Radar/escooter-radar-backend)
- **Jetson Inference Docs:** [Official Guide](https://github.com/dusty-nv/jetson-inference)
- **ML Detection Demo:** [YouTube Tutorial](https://www.youtube.com/watch?v=2XMkPW_sIGg)

---

## üß™ Field Testing Results

**Observations:**
- Morning sessions: higher compliance
- Evening (16:00-18:00): lower compliance
- Detection responsiveness: consistent across sessions
- User behavior: compliance decreased over time

**Insights:**
- High detection reliability (90.74%)
- Need stronger enforcement beyond audio alerts
- Consider visual indicators or mobile notifications
- Behavior change requires sustained intervention

---

## üöÄ Installation

### Prerequisites

| Component | Specification |
|-----------|---------------|
| **Hardware** | NVIDIA Jetson Nano (4GB) |
| **Camera** | CSI or USB (1080p recommended) |
| **Audio** | Speaker/Buzzer for alerts |
| **Power** | 5V 4A DC adapter |
| **Storage** | 32GB+ microSD card |

### Dependencies

```bash
Python 3.8+
PyTorch 1.10+
TensorFlow 2.0+
OpenCV 4.5+
PyAudio
NumPy
```

### Quick Start

```bash
# Clone repository
git clone https://github.com/Methasit-Pun/BEAM-detection-system.git
cd BEAM-detection-system

# Install dependencies
pip3 install -r requirements.txt

# Run detection system
python3 detect_e_scooter.py --camera csi://0 --model models/trained-model/ssd-mobilenet.onnx
```

### Configuration

Edit `config.yaml` to customize:
- Detection threshold
- Alert sensitivity
- Camera input source
- Model path
- Audio alert settings

---

## üîÆ Future Work

**Model Improvements:**
- Expand training data: diverse lighting, angles, clothing
- Reduce false positives in crowded scenes
- Integrate weight sensors for validation

**Enhanced Alerts:**
- LED visual indicators
- Progressive warning system
- Mobile push notifications

**Detection Capabilities:**
- Speed monitoring
- Directional compliance
- Integration with campus enforcement

**Deployment Expansion:**
- Campus gates and intersections
- Parking zone monitoring
- Multi-campus rollout

---

## ü§ù Contributing

Contributions are welcome! Whether you're fixing bugs, improving documentation, or proposing new features.

### How to Contribute

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### Development Guidelines

- Follow PEP 8 style guide for Python code
- Add tests for new features
- Update documentation as needed
- Ensure all tests pass before submitting PR

---

## üìÑ License

MIT License - See [LICENSE](LICENSE) file for details.

---

## üìö References & Acknowledgments

- **NVIDIA Jetson Inference:** [Official Documentation](https://github.com/dusty-nv/jetson-inference)
- **Pascal VOC Format:** [Dataset Specification](http://host.robots.ox.ac.uk/pascal/VOC/)
- **Similar Projects:** [Scooter Radar Backend](https://github.com/Scooter-Radar/escooter-radar-backend)
- **ML Detection Tutorial:** [YouTube Guide](https://www.youtube.com/watch?v=2XMkPW_sIGg)

**Special Thanks:**
- Chulalongkorn University for deployment support
- NVIDIA for Jetson Nano platform
- Open-source computer vision community

---

<div align="center">

### üìä Project Statistics

![GitHub stars](https://img.shields.io/github/stars/Methasit-Pun/BEAM-detection-system?style=social)
![GitHub forks](https://img.shields.io/github/forks/Methasit-Pun/BEAM-detection-system?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/Methasit-Pun/BEAM-detection-system?style=social)

**Made with ‚ù§Ô∏è for campus safety**

[Report Bug](https://github.com/Methasit-Pun/BEAM-detection-system/issues) ¬∑ [Request Feature](https://github.com/Methasit-Pun/BEAM-detection-system/issues) ¬∑ [Documentation](https://github.com/Methasit-Pun/BEAM-detection-system/wiki)

¬© 2024-2026 BEAM Detection System Team. All rights reserved.

</div>
